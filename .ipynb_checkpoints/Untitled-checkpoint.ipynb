{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           isi_tweet  sentimen\n",
      "0  tidak setuju jokowi jadi cawapres capres jokow...         1\n",
      "1  capres jokowi wacapres abraham samad gubernur ...         1\n",
      "2  capres prabowo dan cawapres jokowi dan gubdki ...         1\n",
      "3  jadi skenarionya gini 2014 biar prabowo jadi p...         1\n",
      "4  sby mantan tni dan calon presiden prabowo subi...         1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('tweets.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           isi_tweet  index\n",
      "0  tidak setuju jokowi jadi cawapres capres jokow...      0\n",
      "1  capres jokowi wacapres abraham samad gubernur ...      1\n",
      "2  capres prabowo dan cawapres jokowi dan gubdki ...      2\n",
      "3  jadi skenarionya gini 2014 biar prabowo jadi p...      3\n",
      "4  sby mantan tni dan calon presiden prabowo subi...      4\n",
      "\n",
      "1846 tweets in dataset\n"
     ]
    }
   ],
   "source": [
    "data_text = data[['isi_tweet']]\n",
    "data_text['index'] = data_text.index\n",
    "tweets = data_text\n",
    "print(tweets.head())\n",
    "print(\"\\n{} tweets in dataset\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/brianfrieerich/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import gensim\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import Sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "np.random.seed(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Mereka meniru-nirukannya\n",
      "\n",
      "Stemmed: mereka tiru\n"
     ]
    }
   ],
   "source": [
    "factory = StemmerFactory()\n",
    "indoStemmer = factory.create_stemmer()\n",
    "\n",
    "def indoStem(text):\n",
    "    stemmed = indoStemmer.stem(text)\n",
    "    return stemmed\n",
    "\n",
    "sentence = \"Mereka meniru-nirukannya\"\n",
    "\n",
    "print(\"Original: {}\".format(sentence))\n",
    "\n",
    "output = indoStem(sentence)\n",
    "print(\"\\nStemmed: {}\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result=[]\n",
    "    text = re.sub(\"[^a-zA-Z]+\", \" \", text)\n",
    "    stemmed = indoStem(text)\n",
    "    for word in stemmed.split(' '):\n",
    "        result.append(word)\n",
    "    return result\n",
    "\n",
    "    '''\n",
    "    result.append(words)\n",
    "    return result\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tidak',\n",
       "  'tuju',\n",
       "  'jokowi',\n",
       "  'jadi',\n",
       "  'cawapres',\n",
       "  'capres',\n",
       "  'jokowi',\n",
       "  'harga',\n",
       "  'mati'],\n",
       " ['capres',\n",
       "  'jokowi',\n",
       "  'wacapres',\n",
       "  'abraham',\n",
       "  'samad',\n",
       "  'gubernur',\n",
       "  'ahok',\n",
       "  'saya',\n",
       "  'yakin',\n",
       "  'koruptor',\n",
       "  'abissss'],\n",
       " ['capres',\n",
       "  'prabowo',\n",
       "  'dan',\n",
       "  'cawapres',\n",
       "  'jokowi',\n",
       "  'dan',\n",
       "  'gubdki',\n",
       "  'ahok',\n",
       "  'mantap',\n",
       "  'lanjut',\n",
       "  'buat',\n",
       "  'pak',\n",
       "  'presiden',\n",
       "  'sby',\n",
       "  'bubar',\n",
       "  'saja',\n",
       "  'fpi'],\n",
       " ['jadi',\n",
       "  'skenario',\n",
       "  'gin',\n",
       "  'biar',\n",
       "  'prabowo',\n",
       "  'jadi',\n",
       "  'presiden',\n",
       "  'jokowi',\n",
       "  'tetepgubernur',\n",
       "  'kalau',\n",
       "  'jakarta',\n",
       "  'hasil',\n",
       "  'tidak',\n",
       "  'usah',\n",
       "  'nunggu',\n",
       "  'buat',\n",
       "  'gantiin',\n",
       "  'prabowo'],\n",
       " ['sby',\n",
       "  'mantan',\n",
       "  'tni',\n",
       "  'dan',\n",
       "  'calon',\n",
       "  'presiden',\n",
       "  'prabowo',\n",
       "  'subianto',\n",
       "  'adalah',\n",
       "  'mantan',\n",
       "  'kopassus',\n",
       "  'karena',\n",
       "  'anggoto',\n",
       "  'tni',\n",
       "  'disiplin',\n",
       "  'maka',\n",
       "  'dari',\n",
       "  'itu',\n",
       "  'smw',\n",
       "  'presiden',\n",
       "  'tegas']]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_tweets = list(map(preprocess, tweets['isi_tweet']))\n",
    "processed_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below = 5, no_above = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 1), (6, 1), (79, 2), (83, 1), (95, 1), (96, 2)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(twt) for twt in processed_tweets]\n",
    "bow_corpus[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 5 (\"ahok\") appears 1 time.\n",
      "Word 6 (\"gubernur\") appears 1 time.\n",
      "Word 79 (\"ya\") appears 2 time.\n",
      "Word 83 (\"indonesia\") appears 1 time.\n",
      "Word 95 (\"baru\") appears 1 time.\n",
      "Word 96 (\"gila\") appears 2 time.\n"
     ]
    }
   ],
   "source": [
    "bow_tweet_14 = bow_corpus[15]\n",
    "for i in range(len(bow_tweet_14)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_tweet_14[i][0], \n",
    "                                                     dictionary[bow_tweet_14[i][0]], \n",
    "                                                     bow_tweet_14[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.33771135363355864),\n",
      " (1, 0.7121561583709181),\n",
      " (2, 0.23488586312894935),\n",
      " (3, 0.5688701776535079)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
