{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           isi_tweet  sentimen\n",
      "0  tidak setuju jokowi jadi cawapres capres jokow...         1\n",
      "1  capres jokowi wacapres abraham samad gubernur ...         1\n",
      "2  capres prabowo dan cawapres jokowi dan gubdki ...         1\n",
      "3  jadi skenarionya gini 2014 biar prabowo jadi p...         1\n",
      "4  sby mantan tni dan calon presiden prabowo subi...         1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('tweets.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           isi_tweet  index\n",
      "0  tidak setuju jokowi jadi cawapres capres jokow...      0\n",
      "1  capres jokowi wacapres abraham samad gubernur ...      1\n",
      "2  capres prabowo dan cawapres jokowi dan gubdki ...      2\n",
      "3  jadi skenarionya gini 2014 biar prabowo jadi p...      3\n",
      "4  sby mantan tni dan calon presiden prabowo subi...      4\n",
      "\n",
      "1846 tweets in dataset\n"
     ]
    }
   ],
   "source": [
    "data_text = data[['isi_tweet']]\n",
    "data_text['index'] = data_text.index\n",
    "tweets = data_text\n",
    "print(tweets.head())\n",
    "print(\"\\n{} tweets in dataset\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/brianfrieerich/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import Sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "np.random.seed(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Mereka meniru-nirukannya\n",
      "\n",
      "Stemmed: mereka tiru\n"
     ]
    }
   ],
   "source": [
    "factory = StemmerFactory()\n",
    "indoStemmer = factory.create_stemmer()\n",
    "\n",
    "def indoStem(text):\n",
    "    stemmed = indoStemmer.stem(text)\n",
    "    return stemmed\n",
    "\n",
    "sentence = \"Mereka meniru-nirukannya\"\n",
    "\n",
    "print(\"Original: {}\".format(sentence))\n",
    "\n",
    "output = indoStem(sentence)\n",
    "print(\"\\nStemmed: {}\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = []\n",
    "with open('stopwords.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    stopwords_list = list(reader) \n",
    "    flat_stoplist = [item for sublist in stopwords_list for item in sublist]\n",
    "\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    text = re.sub(\"[^a-zA-Z]+\", \" \", text)\n",
    "    stemmed = indoStem(text)\n",
    "    for word in stemmed.split(' '):\n",
    "        if word not in flat_stoplist:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tuju', 'jokowi', 'cawapres', 'capres', 'jokowi', 'harga', 'mati'],\n",
       " ['capres',\n",
       "  'jokowi',\n",
       "  'wacapres',\n",
       "  'abraham',\n",
       "  'samad',\n",
       "  'gubernur',\n",
       "  'ahok',\n",
       "  'koruptor',\n",
       "  'abissss'],\n",
       " ['capres',\n",
       "  'prabowo',\n",
       "  'cawapres',\n",
       "  'jokowi',\n",
       "  'gubdki',\n",
       "  'ahok',\n",
       "  'mantap',\n",
       "  'presiden',\n",
       "  'sby',\n",
       "  'bubar',\n",
       "  'fpi'],\n",
       " ['skenario',\n",
       "  'gin',\n",
       "  'biar',\n",
       "  'prabowo',\n",
       "  'presiden',\n",
       "  'jokowi',\n",
       "  'tetepgubernur',\n",
       "  'jakarta',\n",
       "  'hasil',\n",
       "  'nunggu',\n",
       "  'gantiin',\n",
       "  'prabowo'],\n",
       " ['sby',\n",
       "  'mantan',\n",
       "  'tni',\n",
       "  'calon',\n",
       "  'presiden',\n",
       "  'prabowo',\n",
       "  'subianto',\n",
       "  'mantan',\n",
       "  'kopassus',\n",
       "  'anggoto',\n",
       "  'tni',\n",
       "  'disiplin',\n",
       "  'smw',\n",
       "  'presiden']]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_tweets = list(map(preprocess, tweets['isi_tweet']))\n",
    "processed_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below = 15, no_above = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1), (3, 1), (20, 2), (22, 1)]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(twt) for twt in processed_tweets]\n",
    "bow_corpus[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 2 (\"ahok\") appears 1 time.\n",
      "Word 3 (\"gubernur\") appears 1 time.\n",
      "Word 20 (\"ya\") appears 2 time.\n",
      "Word 22 (\"indonesia\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_tweet_14 = bow_corpus[15]\n",
    "for i in range(len(bow_tweet_14)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_tweet_14[i][0], \n",
    "                                                     dictionary[bow_tweet_14[i][0]], \n",
    "                                                     bow_tweet_14[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5104769343386324), (1, 0.8598914463513587)]\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.079*\"wiranto\" + 0.071*\"dahlan\" + 0.047*\"iskan\" + 0.036*\"konvensi\" + 0.032*\"calon\" + 0.026*\"jakarta\" + 0.021*\"hatta\" + 0.021*\"pilih\" + 0.018*\"partai\" + 0.018*\"gubernur\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.120*\"hatta\" + 0.058*\"ketua\" + 0.056*\"buka\" + 0.053*\"pan\" + 0.052*\"pencapresan\" + 0.051*\"radjasa\" + 0.051*\"evaluasi\" + 0.049*\"cawapres\" + 0.028*\"gubernur\" + 0.021*\"pimpin\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.069*\"jk\" + 0.051*\"mahfud\" + 0.048*\"partai\" + 0.041*\"md\" + 0.039*\"calon\" + 0.038*\"sby\" + 0.034*\"dahlan\" + 0.027*\"negara\" + 0.025*\"p\" + 0.024*\"survey\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.074*\"arb\" + 0.074*\"jk\" + 0.050*\"gubernur\" + 0.044*\"nyata\" + 0.039*\"tokoh\" + 0.037*\"populer\" + 0.037*\"sosok\" + 0.035*\"bincang\" + 0.029*\"rakyat\" + 0.024*\"hatta\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.073*\"indonesia\" + 0.061*\"dukung\" + 0.046*\"dahlan\" + 0.044*\"cawapres\" + 0.043*\"pilih\" + 0.034*\"pdip\" + 0.034*\"risma\" + 0.032*\"orang\" + 0.025*\"jk\" + 0.025*\"tweet\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics = 5, id2word = dictionary, passes = 2, workers = 4)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.106*\"jk\" + 0.056*\"hatta\" + 0.045*\"cawapres\" + 0.030*\"buka\" + 0.029*\"pan\" + 0.029*\"evaluasi\" + 0.028*\"jakarta\" + 0.028*\"pencapresan\" + 0.028*\"ketua\" + 0.028*\"radjasa\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.050*\"ya\" + 0.046*\"sby\" + 0.042*\"partai\" + 0.030*\"menang\" + 0.029*\"mahfud\" + 0.028*\"konvensi\" + 0.024*\"md\" + 0.023*\"aburizal\" + 0.022*\"bakrie\" + 0.022*\"calon\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.063*\"arb\" + 0.056*\"pdip\" + 0.050*\"risma\" + 0.038*\"bu\" + 0.037*\"mega\" + 0.035*\"ahok\" + 0.030*\"tweet\" + 0.027*\"dahlan\" + 0.024*\"dpd\" + 0.020*\"orang\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.048*\"sosok\" + 0.047*\"nyata\" + 0.047*\"tokoh\" + 0.045*\"populer\" + 0.044*\"bincang\" + 0.039*\"gubernur\" + 0.027*\"wapres\" + 0.024*\"menteri\" + 0.024*\"iklan\" + 0.022*\"hatta\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.059*\"wiranto\" + 0.049*\"dahlan\" + 0.044*\"rakyat\" + 0.044*\"indonesia\" + 0.041*\"calon\" + 0.039*\"iskan\" + 0.034*\"pilih\" + 0.033*\"gubernur\" + 0.030*\"dukung\" + 0.027*\"arb\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, \n",
    "                                             num_topics=5, \n",
    "                                             id2word = dictionary, \n",
    "                                             passes = 2, \n",
    "                                             workers=4)\n",
    "                                             \n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tong di pilih jadi presiden arb na\n",
      "['tong', 'pilih', 'presiden', 'arb', 'na']\n",
      "\n",
      "Score: 0.7270123362541199\t \n",
      "Topic: 0.074*\"arb\" + 0.074*\"jk\" + 0.050*\"gubernur\" + 0.044*\"nyata\" + 0.039*\"tokoh\" + 0.037*\"populer\" + 0.037*\"sosok\" + 0.035*\"bincang\" + 0.029*\"rakyat\" + 0.024*\"hatta\"\n",
      "\n",
      "Score: 0.07101453095674515\t \n",
      "Topic: 0.073*\"indonesia\" + 0.061*\"dukung\" + 0.046*\"dahlan\" + 0.044*\"cawapres\" + 0.043*\"pilih\" + 0.034*\"pdip\" + 0.034*\"risma\" + 0.032*\"orang\" + 0.025*\"jk\" + 0.025*\"tweet\"\n",
      "\n",
      "Score: 0.06833571195602417\t \n",
      "Topic: 0.079*\"wiranto\" + 0.071*\"dahlan\" + 0.047*\"iskan\" + 0.036*\"konvensi\" + 0.032*\"calon\" + 0.026*\"jakarta\" + 0.021*\"hatta\" + 0.021*\"pilih\" + 0.018*\"partai\" + 0.018*\"gubernur\"\n",
      "\n",
      "Score: 0.06689741462469101\t \n",
      "Topic: 0.069*\"jk\" + 0.051*\"mahfud\" + 0.048*\"partai\" + 0.041*\"md\" + 0.039*\"calon\" + 0.038*\"sby\" + 0.034*\"dahlan\" + 0.027*\"negara\" + 0.025*\"p\" + 0.024*\"survey\"\n",
      "\n",
      "Score: 0.06674003601074219\t \n",
      "Topic: 0.120*\"hatta\" + 0.058*\"ketua\" + 0.056*\"buka\" + 0.053*\"pan\" + 0.052*\"pencapresan\" + 0.051*\"radjasa\" + 0.051*\"evaluasi\" + 0.049*\"cawapres\" + 0.028*\"gubernur\" + 0.021*\"pimpin\"\n"
     ]
    }
   ],
   "source": [
    "document_num = 12\n",
    "print(data.iloc[document_num, 0])\n",
    "\n",
    "print(processed_tweets[document_num])\n",
    "\n",
    "for index, score in sorted(lda_model[bow_corpus[document_num]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.727607250213623\t \n",
      "Topic: 0.059*\"wiranto\" + 0.049*\"dahlan\" + 0.044*\"rakyat\" + 0.044*\"indonesia\" + 0.041*\"calon\" + 0.039*\"iskan\" + 0.034*\"pilih\" + 0.033*\"gubernur\" + 0.030*\"dukung\" + 0.027*\"arb\"\n",
      "\n",
      "Score: 0.07026755064725876\t \n",
      "Topic: 0.063*\"arb\" + 0.056*\"pdip\" + 0.050*\"risma\" + 0.038*\"bu\" + 0.037*\"mega\" + 0.035*\"ahok\" + 0.030*\"tweet\" + 0.027*\"dahlan\" + 0.024*\"dpd\" + 0.020*\"orang\"\n",
      "\n",
      "Score: 0.06764436513185501\t \n",
      "Topic: 0.050*\"ya\" + 0.046*\"sby\" + 0.042*\"partai\" + 0.030*\"menang\" + 0.029*\"mahfud\" + 0.028*\"konvensi\" + 0.024*\"md\" + 0.023*\"aburizal\" + 0.022*\"bakrie\" + 0.022*\"calon\"\n",
      "\n",
      "Score: 0.06739744544029236\t \n",
      "Topic: 0.106*\"jk\" + 0.056*\"hatta\" + 0.045*\"cawapres\" + 0.030*\"buka\" + 0.029*\"pan\" + 0.029*\"evaluasi\" + 0.028*\"jakarta\" + 0.028*\"pencapresan\" + 0.028*\"ketua\" + 0.028*\"radjasa\"\n",
      "\n",
      "Score: 0.06708336621522903\t \n",
      "Topic: 0.048*\"sosok\" + 0.047*\"nyata\" + 0.047*\"tokoh\" + 0.045*\"populer\" + 0.044*\"bincang\" + 0.039*\"gubernur\" + 0.027*\"wapres\" + 0.024*\"menteri\" + 0.024*\"iklan\" + 0.022*\"hatta\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[document_num]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.48706871271133423\t Topic: 0.073*\"indonesia\" + 0.061*\"dukung\" + 0.046*\"dahlan\" + 0.044*\"cawapres\" + 0.043*\"pilih\"\n",
      "Score: 0.3627563714981079\t Topic: 0.069*\"jk\" + 0.051*\"mahfud\" + 0.048*\"partai\" + 0.041*\"md\" + 0.039*\"calon\"\n",
      "Score: 0.05010193958878517\t Topic: 0.120*\"hatta\" + 0.058*\"ketua\" + 0.056*\"buka\" + 0.053*\"pan\" + 0.052*\"pencapresan\"\n",
      "Score: 0.05004393681883812\t Topic: 0.079*\"wiranto\" + 0.071*\"dahlan\" + 0.047*\"iskan\" + 0.036*\"konvensi\" + 0.032*\"calon\"\n",
      "Score: 0.05002905800938606\t Topic: 0.074*\"arb\" + 0.074*\"jk\" + 0.050*\"gubernur\" + 0.044*\"nyata\" + 0.039*\"tokoh\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = \"Saya mendukung Jokowi dan Basuki! PDI-P selamanya!\"\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
