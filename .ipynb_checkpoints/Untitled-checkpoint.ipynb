{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           isi_tweet  sentimen\n",
      "0  tidak setuju jokowi jadi cawapres capres jokow...         1\n",
      "1  capres jokowi wacapres abraham samad gubernur ...         1\n",
      "2  capres prabowo dan cawapres jokowi dan gubdki ...         1\n",
      "3  jadi skenarionya gini 2014 biar prabowo jadi p...         1\n",
      "4  sby mantan tni dan calon presiden prabowo subi...         1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('tweets.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           isi_tweet  index\n",
      "0  tidak setuju jokowi jadi cawapres capres jokow...      0\n",
      "1  capres jokowi wacapres abraham samad gubernur ...      1\n",
      "2  capres prabowo dan cawapres jokowi dan gubdki ...      2\n",
      "3  jadi skenarionya gini 2014 biar prabowo jadi p...      3\n",
      "4  sby mantan tni dan calon presiden prabowo subi...      4\n",
      "\n",
      "1846 tweets in dataset\n"
     ]
    }
   ],
   "source": [
    "data_text = data[['isi_tweet']]\n",
    "data_text['index'] = data_text.index\n",
    "tweets = data_text\n",
    "print(tweets.head())\n",
    "print(\"\\n{} tweets in dataset\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/brianfrieerich/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import gensim\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import Sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "np.random.seed(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Mereka meniru-nirukannya\n",
      "\n",
      "Stemmed: mereka tiru\n"
     ]
    }
   ],
   "source": [
    "factory = StemmerFactory()\n",
    "indoStemmer = factory.create_stemmer()\n",
    "\n",
    "def indoStem(text):\n",
    "    stemmed = indoStemmer.stem(text)\n",
    "    return stemmed\n",
    "\n",
    "sentence = \"Mereka meniru-nirukannya\"\n",
    "\n",
    "print(\"Original: {}\".format(sentence))\n",
    "\n",
    "output = indoStem(sentence)\n",
    "print(\"\\nStemmed: {}\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result=[]\n",
    "    text = re.sub(\"[^a-zA-Z]+\", \" \", text)\n",
    "    stemmed = indoStem(text)\n",
    "    for word in stemmed.split(' '):\n",
    "        result.append(word)\n",
    "    return result\n",
    "\n",
    "    '''\n",
    "    result.append(words)\n",
    "    return result\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tidak',\n",
       "  'tuju',\n",
       "  'jokowi',\n",
       "  'jadi',\n",
       "  'cawapres',\n",
       "  'capres',\n",
       "  'jokowi',\n",
       "  'harga',\n",
       "  'mati'],\n",
       " ['capres',\n",
       "  'jokowi',\n",
       "  'wacapres',\n",
       "  'abraham',\n",
       "  'samad',\n",
       "  'gubernur',\n",
       "  'ahok',\n",
       "  'saya',\n",
       "  'yakin',\n",
       "  'koruptor',\n",
       "  'abissss'],\n",
       " ['capres',\n",
       "  'prabowo',\n",
       "  'dan',\n",
       "  'cawapres',\n",
       "  'jokowi',\n",
       "  'dan',\n",
       "  'gubdki',\n",
       "  'ahok',\n",
       "  'mantap',\n",
       "  'lanjut',\n",
       "  'buat',\n",
       "  'pak',\n",
       "  'presiden',\n",
       "  'sby',\n",
       "  'bubar',\n",
       "  'saja',\n",
       "  'fpi'],\n",
       " ['jadi',\n",
       "  'skenario',\n",
       "  'gin',\n",
       "  'biar',\n",
       "  'prabowo',\n",
       "  'jadi',\n",
       "  'presiden',\n",
       "  'jokowi',\n",
       "  'tetepgubernur',\n",
       "  'kalau',\n",
       "  'jakarta',\n",
       "  'hasil',\n",
       "  'tidak',\n",
       "  'usah',\n",
       "  'nunggu',\n",
       "  'buat',\n",
       "  'gantiin',\n",
       "  'prabowo'],\n",
       " ['sby',\n",
       "  'mantan',\n",
       "  'tni',\n",
       "  'dan',\n",
       "  'calon',\n",
       "  'presiden',\n",
       "  'prabowo',\n",
       "  'subianto',\n",
       "  'adalah',\n",
       "  'mantan',\n",
       "  'kopassus',\n",
       "  'karena',\n",
       "  'anggoto',\n",
       "  'tni',\n",
       "  'disiplin',\n",
       "  'maka',\n",
       "  'dari',\n",
       "  'itu',\n",
       "  'smw',\n",
       "  'presiden',\n",
       "  'tegas']]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_tweets = list(map(preprocess, tweets['isi_tweet']))\n",
    "processed_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below = 5, no_above = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 1), (6, 1), (79, 2), (83, 1), (95, 1), (96, 2)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(twt) for twt in processed_tweets]\n",
    "bow_corpus[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 5 (\"ahok\") appears 1 time.\n",
      "Word 6 (\"gubernur\") appears 1 time.\n",
      "Word 79 (\"ya\") appears 2 time.\n",
      "Word 83 (\"indonesia\") appears 1 time.\n",
      "Word 95 (\"baru\") appears 1 time.\n",
      "Word 96 (\"gila\") appears 2 time.\n"
     ]
    }
   ],
   "source": [
    "bow_tweet_14 = bow_corpus[15]\n",
    "for i in range(len(bow_tweet_14)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_tweet_14[i][0], \n",
    "                                                     dictionary[bow_tweet_14[i][0]], \n",
    "                                                     bow_tweet_14[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.33771135363355864),\n",
      " (1, 0.7121561583709181),\n",
      " (2, 0.23488586312894935),\n",
      " (3, 0.5688701776535079)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.042*\"wakil\" + 0.039*\"dan\" + 0.035*\"kalla\" + 0.035*\"jusuf\" + 0.035*\"mantan\" + 0.031*\"gubernur\" + 0.027*\"bagai\" + 0.026*\"nyata\" + 0.025*\"dalam\" + 0.024*\"tokoh\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.038*\"dahlan\" + 0.030*\"saya\" + 0.020*\"iskan\" + 0.015*\"pak\" + 0.014*\"indonesia\" + 0.013*\"kalau\" + 0.011*\"megawati\" + 0.010*\"maju\" + 0.010*\"di\" + 0.010*\"pilih\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.039*\"wakil\" + 0.032*\"megawati\" + 0.024*\"jusuf\" + 0.023*\"mantan\" + 0.023*\"kalla\" + 0.021*\"yang\" + 0.021*\"prabowo\" + 0.019*\"dan\" + 0.016*\"pada\" + 0.014*\"di\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.040*\"yang\" + 0.021*\"dan\" + 0.017*\"bisa\" + 0.017*\"tidak\" + 0.016*\"pada\" + 0.016*\"di\" + 0.015*\"prabowo\" + 0.014*\"ada\" + 0.014*\"arb\" + 0.013*\"kalau\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.035*\"yang\" + 0.023*\"di\" + 0.019*\"akan\" + 0.016*\"jk\" + 0.013*\"dan\" + 0.013*\"bagai\" + 0.012*\"arb\" + 0.011*\"wakil\" + 0.009*\"risma\" + 0.009*\"megawati\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.035*\"saya\" + 0.026*\"yang\" + 0.021*\"megawati\" + 0.018*\"di\" + 0.014*\"mega\" + 0.012*\"calon\" + 0.011*\"kalla\" + 0.011*\"followradiopepatah\" + 0.011*\"apa\" + 0.011*\"prabowo\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.057*\"di\" + 0.034*\"jk\" + 0.022*\"wakil\" + 0.019*\"kalla\" + 0.019*\"jusuf\" + 0.018*\"wiranto\" + 0.018*\"mantan\" + 0.017*\"tidak\" + 0.016*\"calon\" + 0.013*\"arb\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.057*\"tidak\" + 0.056*\"hatta\" + 0.040*\"prabowo\" + 0.031*\"mungkin\" + 0.029*\"jika\" + 0.028*\"cawapres\" + 0.028*\"ketua\" + 0.027*\"pan\" + 0.026*\"umum\" + 0.025*\"buka\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics = 8, id2word = dictionary, passes = 2, workers = 4)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.018*\"saya\" + 0.014*\"dahlan\" + 0.012*\"pilih\" + 0.012*\"akan\" + 0.012*\"wapres\" + 0.010*\"bagai\" + 0.010*\"prabowo\" + 0.010*\"jk\" + 0.009*\"di\" + 0.009*\"yang\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.024*\"populer\" + 0.024*\"bincang\" + 0.024*\"sosok\" + 0.023*\"tokoh\" + 0.023*\"nyata\" + 0.023*\"gubernur\" + 0.021*\"dalam\" + 0.021*\"wakil\" + 0.020*\"bagai\" + 0.019*\"dan\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.016*\"di\" + 0.011*\"mantan\" + 0.011*\"jk\" + 0.011*\"megawati\" + 0.010*\"yang\" + 0.010*\"arb\" + 0.008*\"wakil\" + 0.008*\"bisa\" + 0.008*\"calon\" + 0.008*\"itu\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.014*\"dahlan\" + 0.013*\"iskan\" + 0.011*\"jk\" + 0.010*\"soal\" + 0.010*\"prabowo\" + 0.010*\"tidak\" + 0.010*\"kabar\" + 0.010*\"yang\" + 0.009*\"berita\" + 0.008*\"milih\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.014*\"mahfud\" + 0.013*\"md\" + 0.012*\"jk\" + 0.011*\"prab\" + 0.010*\"news\" + 0.009*\"dan\" + 0.008*\"dahlan\" + 0.008*\"hatta\" + 0.008*\"sby\" + 0.007*\"ketua\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.012*\"wiranto\" + 0.010*\"dahlan\" + 0.010*\"di\" + 0.010*\"saya\" + 0.009*\"ri\" + 0.008*\"yang\" + 0.008*\"pada\" + 0.008*\"megawati\" + 0.007*\"sama\" + 0.007*\"dan\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.040*\"hatta\" + 0.024*\"pan\" + 0.023*\"evaluasi\" + 0.022*\"radjasa\" + 0.022*\"buka\" + 0.022*\"pencapresan\" + 0.022*\"mungkin\" + 0.021*\"umum\" + 0.021*\"ketua\" + 0.020*\"jika\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.016*\"megawati\" + 0.015*\"pak\" + 0.014*\"arb\" + 0.011*\"wakil\" + 0.011*\"mantan\" + 0.008*\"yang\" + 0.008*\"jusuf\" + 0.008*\"kalla\" + 0.008*\"di\" + 0.008*\"tidak\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.020*\"prabowo\" + 0.014*\"yang\" + 0.011*\"saya\" + 0.009*\"tidak\" + 0.009*\"followradiopepatah\" + 0.008*\"ya\" + 0.008*\"dahlan\" + 0.008*\"kalau\" + 0.008*\"gerindra\" + 0.007*\"lain\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.012*\"megawati\" + 0.011*\"yang\" + 0.010*\"menang\" + 0.010*\"prabowo\" + 0.010*\"bisa\" + 0.010*\"di\" + 0.010*\"bu\" + 0.009*\"indonesia\" + 0.009*\"tidak\" + 0.008*\"pilih\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, \n",
    "                                             num_topics=10, \n",
    "                                             id2word = dictionary, \n",
    "                                             passes = 2, \n",
    "                                             workers=4)\n",
    "                                             \n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tong di pilih jadi presiden arb na\n",
      "['tong', 'di', 'pilih', 'jadi', 'presiden', 'arb', 'na']\n",
      "\n",
      "Score: 0.7749497890472412\t \n",
      "Topic: 0.016*\"di\" + 0.011*\"mantan\" + 0.011*\"jk\" + 0.011*\"megawati\" + 0.010*\"yang\" + 0.010*\"arb\" + 0.008*\"wakil\" + 0.008*\"bisa\" + 0.008*\"calon\" + 0.008*\"itu\"\n",
      "\n",
      "Score: 0.025012562051415443\t \n",
      "Topic: 0.018*\"saya\" + 0.014*\"dahlan\" + 0.012*\"pilih\" + 0.012*\"akan\" + 0.012*\"wapres\" + 0.010*\"bagai\" + 0.010*\"prabowo\" + 0.010*\"jk\" + 0.009*\"di\" + 0.009*\"yang\"\n",
      "\n",
      "Score: 0.025008508935570717\t \n",
      "Topic: 0.012*\"megawati\" + 0.011*\"yang\" + 0.010*\"menang\" + 0.010*\"prabowo\" + 0.010*\"bisa\" + 0.010*\"di\" + 0.010*\"bu\" + 0.009*\"indonesia\" + 0.009*\"tidak\" + 0.008*\"pilih\"\n",
      "\n",
      "Score: 0.02500646375119686\t \n",
      "Topic: 0.016*\"megawati\" + 0.015*\"pak\" + 0.014*\"arb\" + 0.011*\"wakil\" + 0.011*\"mantan\" + 0.008*\"yang\" + 0.008*\"jusuf\" + 0.008*\"kalla\" + 0.008*\"di\" + 0.008*\"tidak\"\n",
      "\n",
      "Score: 0.02500627189874649\t \n",
      "Topic: 0.012*\"wiranto\" + 0.010*\"dahlan\" + 0.010*\"di\" + 0.010*\"saya\" + 0.009*\"ri\" + 0.008*\"yang\" + 0.008*\"pada\" + 0.008*\"megawati\" + 0.007*\"sama\" + 0.007*\"dan\"\n",
      "\n",
      "Score: 0.025006093084812164\t \n",
      "Topic: 0.020*\"prabowo\" + 0.014*\"yang\" + 0.011*\"saya\" + 0.009*\"tidak\" + 0.009*\"followradiopepatah\" + 0.008*\"ya\" + 0.008*\"dahlan\" + 0.008*\"kalau\" + 0.008*\"gerindra\" + 0.007*\"lain\"\n",
      "\n",
      "Score: 0.025003738701343536\t \n",
      "Topic: 0.014*\"dahlan\" + 0.013*\"iskan\" + 0.011*\"jk\" + 0.010*\"soal\" + 0.010*\"prabowo\" + 0.010*\"tidak\" + 0.010*\"kabar\" + 0.010*\"yang\" + 0.009*\"berita\" + 0.008*\"milih\"\n",
      "\n",
      "Score: 0.025002852082252502\t \n",
      "Topic: 0.040*\"hatta\" + 0.024*\"pan\" + 0.023*\"evaluasi\" + 0.022*\"radjasa\" + 0.022*\"buka\" + 0.022*\"pencapresan\" + 0.022*\"mungkin\" + 0.021*\"umum\" + 0.021*\"ketua\" + 0.020*\"jika\"\n",
      "\n",
      "Score: 0.02500229701399803\t \n",
      "Topic: 0.014*\"mahfud\" + 0.013*\"md\" + 0.012*\"jk\" + 0.011*\"prab\" + 0.010*\"news\" + 0.009*\"dan\" + 0.008*\"dahlan\" + 0.008*\"hatta\" + 0.008*\"sby\" + 0.007*\"ketua\"\n",
      "\n",
      "Score: 0.025001423433423042\t \n",
      "Topic: 0.024*\"populer\" + 0.024*\"bincang\" + 0.024*\"sosok\" + 0.023*\"tokoh\" + 0.023*\"nyata\" + 0.023*\"gubernur\" + 0.021*\"dalam\" + 0.021*\"wakil\" + 0.020*\"bagai\" + 0.019*\"dan\"\n"
     ]
    }
   ],
   "source": [
    "document_num = 12\n",
    "print(data.iloc[document_num, 0])\n",
    "\n",
    "print(processed_tweets[document_num])\n",
    "\n",
    "for index, score in sorted(lda_model_tfidf[bow_corpus[document_num]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8904606699943542\t Topic: 0.035*\"saya\" + 0.026*\"yang\" + 0.021*\"megawati\" + 0.018*\"di\" + 0.014*\"mega\"\n",
      "Score: 0.01566990464925766\t Topic: 0.040*\"yang\" + 0.021*\"dan\" + 0.017*\"bisa\" + 0.017*\"tidak\" + 0.016*\"pada\"\n",
      "Score: 0.015664348378777504\t Topic: 0.042*\"wakil\" + 0.039*\"dan\" + 0.035*\"kalla\" + 0.035*\"jusuf\" + 0.035*\"mantan\"\n",
      "Score: 0.0156511589884758\t Topic: 0.039*\"wakil\" + 0.032*\"megawati\" + 0.024*\"jusuf\" + 0.023*\"mantan\" + 0.023*\"kalla\"\n",
      "Score: 0.015649324283003807\t Topic: 0.038*\"dahlan\" + 0.030*\"saya\" + 0.020*\"iskan\" + 0.015*\"pak\" + 0.014*\"indonesia\"\n",
      "Score: 0.015637444332242012\t Topic: 0.035*\"yang\" + 0.023*\"di\" + 0.019*\"akan\" + 0.016*\"jk\" + 0.013*\"dan\"\n",
      "Score: 0.01563376747071743\t Topic: 0.057*\"di\" + 0.034*\"jk\" + 0.022*\"wakil\" + 0.019*\"kalla\" + 0.019*\"jusuf\"\n",
      "Score: 0.015633374452590942\t Topic: 0.057*\"tidak\" + 0.056*\"hatta\" + 0.040*\"prabowo\" + 0.031*\"mungkin\" + 0.029*\"jika\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = \"Saya mendukung Jokowi dan Basuki! PDI-P selamanya!\"\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
