{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           isi_tweet  sentimen\n",
      "0  tidak setuju jokowi jadi cawapres capres jokow...         1\n",
      "1  capres jokowi wacapres abraham samad gubernur ...         1\n",
      "2  capres prabowo dan cawapres jokowi dan gubdki ...         1\n",
      "3  jadi skenarionya gini 2014 biar prabowo jadi p...         1\n",
      "4  sby mantan tni dan calon presiden prabowo subi...         1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('tweets.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           isi_tweet  index\n",
      "0  tidak setuju jokowi jadi cawapres capres jokow...      0\n",
      "1  capres jokowi wacapres abraham samad gubernur ...      1\n",
      "2  capres prabowo dan cawapres jokowi dan gubdki ...      2\n",
      "3  jadi skenarionya gini 2014 biar prabowo jadi p...      3\n",
      "4  sby mantan tni dan calon presiden prabowo subi...      4\n",
      "\n",
      "1846 tweets in dataset\n"
     ]
    }
   ],
   "source": [
    "data_text = data[['isi_tweet']]\n",
    "data_text['index'] = data_text.index\n",
    "tweets = data_text\n",
    "print(tweets.head())\n",
    "print(\"\\n{} tweets in dataset\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/brianfrieerich/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import Sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "np.random.seed(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Mereka meniru-nirukannya\n",
      "\n",
      "Stemmed: mereka tiru\n"
     ]
    }
   ],
   "source": [
    "factory = StemmerFactory()\n",
    "indoStemmer = factory.create_stemmer()\n",
    "\n",
    "def indoStem(text):\n",
    "    stemmed = indoStemmer.stem(text)\n",
    "    return stemmed\n",
    "\n",
    "sentence = \"Mereka meniru-nirukannya\"\n",
    "\n",
    "print(\"Original: {}\".format(sentence))\n",
    "\n",
    "output = indoStem(sentence)\n",
    "print(\"\\nStemmed: {}\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result=[]\n",
    "    text = re.sub(\"[^a-zA-Z]+\", \" \", text)\n",
    "    stemmed = indoStem(text)\n",
    "    for word in stemmed.split(' '):\n",
    "        result.append(word)\n",
    "    return result\n",
    "\n",
    "    '''\n",
    "    result.append(words)\n",
    "    return result\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tidak',\n",
       "  'tuju',\n",
       "  'jokowi',\n",
       "  'jadi',\n",
       "  'cawapres',\n",
       "  'capres',\n",
       "  'jokowi',\n",
       "  'harga',\n",
       "  'mati'],\n",
       " ['capres',\n",
       "  'jokowi',\n",
       "  'wacapres',\n",
       "  'abraham',\n",
       "  'samad',\n",
       "  'gubernur',\n",
       "  'ahok',\n",
       "  'saya',\n",
       "  'yakin',\n",
       "  'koruptor',\n",
       "  'abissss'],\n",
       " ['capres',\n",
       "  'prabowo',\n",
       "  'dan',\n",
       "  'cawapres',\n",
       "  'jokowi',\n",
       "  'dan',\n",
       "  'gubdki',\n",
       "  'ahok',\n",
       "  'mantap',\n",
       "  'lanjut',\n",
       "  'buat',\n",
       "  'pak',\n",
       "  'presiden',\n",
       "  'sby',\n",
       "  'bubar',\n",
       "  'saja',\n",
       "  'fpi'],\n",
       " ['jadi',\n",
       "  'skenario',\n",
       "  'gin',\n",
       "  'biar',\n",
       "  'prabowo',\n",
       "  'jadi',\n",
       "  'presiden',\n",
       "  'jokowi',\n",
       "  'tetepgubernur',\n",
       "  'kalau',\n",
       "  'jakarta',\n",
       "  'hasil',\n",
       "  'tidak',\n",
       "  'usah',\n",
       "  'nunggu',\n",
       "  'buat',\n",
       "  'gantiin',\n",
       "  'prabowo'],\n",
       " ['sby',\n",
       "  'mantan',\n",
       "  'tni',\n",
       "  'dan',\n",
       "  'calon',\n",
       "  'presiden',\n",
       "  'prabowo',\n",
       "  'subianto',\n",
       "  'adalah',\n",
       "  'mantan',\n",
       "  'kopassus',\n",
       "  'karena',\n",
       "  'anggoto',\n",
       "  'tni',\n",
       "  'disiplin',\n",
       "  'maka',\n",
       "  'dari',\n",
       "  'itu',\n",
       "  'smw',\n",
       "  'presiden',\n",
       "  'tegas']]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_tweets = list(map(preprocess, tweets['isi_tweet']))\n",
    "processed_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below = 5, no_above = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 1), (5, 1), (77, 2), (81, 1), (93, 1), (94, 2)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(twt) for twt in processed_tweets]\n",
    "bow_corpus[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 4 (\"ahok\") appears 1 time.\n",
      "Word 5 (\"gubernur\") appears 1 time.\n",
      "Word 77 (\"ya\") appears 2 time.\n",
      "Word 81 (\"indonesia\") appears 1 time.\n",
      "Word 93 (\"baru\") appears 1 time.\n",
      "Word 94 (\"gila\") appears 2 time.\n"
     ]
    }
   ],
   "source": [
    "bow_tweet_14 = bow_corpus[15]\n",
    "for i in range(len(bow_tweet_14)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_tweet_14[i][0], \n",
    "                                                     dictionary[bow_tweet_14[i][0]], \n",
    "                                                     bow_tweet_14[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.34743145805198594), (1, 0.7326536398654326), (2, 0.5852435612185782)]\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.033*\"di\" + 0.020*\"dahlan\" + 0.019*\"rakyat\" + 0.019*\"jk\" + 0.019*\"pada\" + 0.018*\"prabowo\" + 0.015*\"konvensi\" + 0.014*\"kalla\" + 0.014*\"hatta\" + 0.014*\"jusuf\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.038*\"mantan\" + 0.035*\"kalla\" + 0.034*\"jusuf\" + 0.034*\"dan\" + 0.027*\"dalam\" + 0.026*\"tokoh\" + 0.026*\"bagai\" + 0.024*\"gubernur\" + 0.024*\"nyata\" + 0.022*\"sosok\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.048*\"hatta\" + 0.026*\"jika\" + 0.025*\"ketua\" + 0.024*\"mungkin\" + 0.023*\"umum\" + 0.022*\"pan\" + 0.022*\"buka\" + 0.021*\"bisa\" + 0.020*\"cawapres\" + 0.020*\"evaluasi\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.024*\"mau\" + 0.024*\"pdip\" + 0.016*\"ada\" + 0.016*\"dahlan\" + 0.015*\"di\" + 0.015*\"megawati\" + 0.013*\"dukung\" + 0.013*\"dengan\" + 0.012*\"indonesia\" + 0.012*\"kalau\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.036*\"saya\" + 0.026*\"di\" + 0.021*\"megawati\" + 0.018*\"dahlan\" + 0.016*\"prabowo\" + 0.013*\"calon\" + 0.012*\"jk\" + 0.011*\"hanya\" + 0.011*\"dan\" + 0.010*\"jakarta\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.051*\"prabowo\" + 0.021*\"saya\" + 0.021*\"kalau\" + 0.020*\"pak\" + 0.020*\"megawati\" + 0.019*\"untuk\" + 0.017*\"dan\" + 0.012*\"risma\" + 0.012*\"menang\" + 0.010*\"indonesia\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.025*\"di\" + 0.023*\"dan\" + 0.018*\"kalla\" + 0.018*\"jusuf\" + 0.017*\"ke\" + 0.017*\"mantan\" + 0.014*\"jk\" + 0.014*\"bisa\" + 0.013*\"kalau\" + 0.013*\"lebih\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.034*\"wiranto\" + 0.034*\"jk\" + 0.017*\"calon\" + 0.016*\"mantan\" + 0.016*\"dan\" + 0.015*\"tak\" + 0.015*\"di\" + 0.014*\"saya\" + 0.014*\"pilih\" + 0.014*\"kalla\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics = 8, id2word = dictionary, passes = 2, workers = 4)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.012*\"di\" + 0.012*\"dahlan\" + 0.012*\"soal\" + 0.011*\"pilih\" + 0.010*\"prabowo\" + 0.010*\"iskan\" + 0.010*\"tanya\" + 0.010*\"dukung\" + 0.008*\"jk\" + 0.008*\"jawab\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.013*\"prabowo\" + 0.012*\"wapres\" + 0.011*\"risma\" + 0.010*\"cocok\" + 0.009*\"gubernur\" + 0.009*\"mau\" + 0.009*\"sudah\" + 0.008*\"di\" + 0.008*\"dengan\" + 0.008*\"jk\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.014*\"arb\" + 0.010*\"ekonomi\" + 0.010*\"ri\" + 0.009*\"rakyat\" + 0.009*\"punya\" + 0.008*\"kan\" + 0.008*\"calon\" + 0.008*\"di\" + 0.008*\"maju\" + 0.007*\"partai\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.040*\"hatta\" + 0.026*\"ketua\" + 0.024*\"radjasa\" + 0.024*\"pan\" + 0.024*\"evaluasi\" + 0.024*\"pencapresan\" + 0.023*\"buka\" + 0.023*\"mungkin\" + 0.022*\"umum\" + 0.022*\"jika\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.020*\"jusuf\" + 0.019*\"bincang\" + 0.019*\"mantan\" + 0.019*\"kalla\" + 0.019*\"populer\" + 0.019*\"nyata\" + 0.019*\"sosok\" + 0.019*\"tokoh\" + 0.019*\"dan\" + 0.018*\"gubernur\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.012*\"iskan\" + 0.010*\"saya\" + 0.010*\"dahlan\" + 0.009*\"islam\" + 0.009*\"kalau\" + 0.009*\"ahok\" + 0.009*\"prabowo\" + 0.008*\"pasang\" + 0.008*\"widodo\" + 0.008*\"jk\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.017*\"saya\" + 0.012*\"pada\" + 0.012*\"jk\" + 0.011*\"di\" + 0.011*\"prabowo\" + 0.010*\"arb\" + 0.010*\"megawati\" + 0.010*\"survey\" + 0.010*\"mantan\" + 0.009*\"pak\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.017*\"megawati\" + 0.011*\"dahlan\" + 0.009*\"ical\" + 0.008*\"nama\" + 0.008*\"lebih\" + 0.008*\"prabowo\" + 0.008*\"saya\" + 0.007*\"prab\" + 0.007*\"tak\" + 0.007*\"masa\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.011*\"megawati\" + 0.010*\"dahlan\" + 0.009*\"jk\" + 0.009*\"ini\" + 0.008*\"saya\" + 0.008*\"mantan\" + 0.008*\"ada\" + 0.008*\"di\" + 0.007*\"anis\" + 0.007*\"akan\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.012*\"berita\" + 0.011*\"wiranto\" + 0.011*\"kabar\" + 0.009*\"arb\" + 0.009*\"ya\" + 0.008*\"saja\" + 0.008*\"di\" + 0.008*\"lebih\" + 0.008*\"prabowo\" + 0.008*\"jk\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, \n",
    "                                             num_topics=10, \n",
    "                                             id2word = dictionary, \n",
    "                                             passes = 2, \n",
    "                                             workers=4)\n",
    "                                             \n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tong di pilih jadi presiden arb na\n",
      "['tong', 'di', 'pilih', 'jadi', 'presiden', 'arb', 'na']\n",
      "\n",
      "Score: 0.7749477624893188\t \n",
      "Topic: 0.012*\"di\" + 0.012*\"dahlan\" + 0.012*\"soal\" + 0.011*\"pilih\" + 0.010*\"prabowo\" + 0.010*\"iskan\" + 0.010*\"tanya\" + 0.010*\"dukung\" + 0.008*\"jk\" + 0.008*\"jawab\"\n",
      "\n",
      "Score: 0.025010446086525917\t \n",
      "Topic: 0.017*\"saya\" + 0.012*\"pada\" + 0.012*\"jk\" + 0.011*\"di\" + 0.011*\"prabowo\" + 0.010*\"arb\" + 0.010*\"megawati\" + 0.010*\"survey\" + 0.010*\"mantan\" + 0.009*\"pak\"\n",
      "\n",
      "Score: 0.02501033991575241\t \n",
      "Topic: 0.014*\"arb\" + 0.010*\"ekonomi\" + 0.010*\"ri\" + 0.009*\"rakyat\" + 0.009*\"punya\" + 0.008*\"kan\" + 0.008*\"calon\" + 0.008*\"di\" + 0.008*\"maju\" + 0.007*\"partai\"\n",
      "\n",
      "Score: 0.025007732212543488\t \n",
      "Topic: 0.012*\"berita\" + 0.011*\"wiranto\" + 0.011*\"kabar\" + 0.009*\"arb\" + 0.009*\"ya\" + 0.008*\"saja\" + 0.008*\"di\" + 0.008*\"lebih\" + 0.008*\"prabowo\" + 0.008*\"jk\"\n",
      "\n",
      "Score: 0.02500588446855545\t \n",
      "Topic: 0.020*\"jusuf\" + 0.019*\"bincang\" + 0.019*\"mantan\" + 0.019*\"kalla\" + 0.019*\"populer\" + 0.019*\"nyata\" + 0.019*\"sosok\" + 0.019*\"tokoh\" + 0.019*\"dan\" + 0.018*\"gubernur\"\n",
      "\n",
      "Score: 0.025004364550113678\t \n",
      "Topic: 0.017*\"megawati\" + 0.011*\"dahlan\" + 0.009*\"ical\" + 0.008*\"nama\" + 0.008*\"lebih\" + 0.008*\"prabowo\" + 0.008*\"saya\" + 0.007*\"prab\" + 0.007*\"tak\" + 0.007*\"masa\"\n",
      "\n",
      "Score: 0.025004323571920395\t \n",
      "Topic: 0.011*\"megawati\" + 0.010*\"dahlan\" + 0.009*\"jk\" + 0.009*\"ini\" + 0.008*\"saya\" + 0.008*\"mantan\" + 0.008*\"ada\" + 0.008*\"di\" + 0.007*\"anis\" + 0.007*\"akan\"\n",
      "\n",
      "Score: 0.025003582239151\t \n",
      "Topic: 0.012*\"iskan\" + 0.010*\"saya\" + 0.010*\"dahlan\" + 0.009*\"islam\" + 0.009*\"kalau\" + 0.009*\"ahok\" + 0.009*\"prabowo\" + 0.008*\"pasang\" + 0.008*\"widodo\" + 0.008*\"jk\"\n",
      "\n",
      "Score: 0.025002913549542427\t \n",
      "Topic: 0.013*\"prabowo\" + 0.012*\"wapres\" + 0.011*\"risma\" + 0.010*\"cocok\" + 0.009*\"gubernur\" + 0.009*\"mau\" + 0.009*\"sudah\" + 0.008*\"di\" + 0.008*\"dengan\" + 0.008*\"jk\"\n",
      "\n",
      "Score: 0.025002678856253624\t \n",
      "Topic: 0.040*\"hatta\" + 0.026*\"ketua\" + 0.024*\"radjasa\" + 0.024*\"pan\" + 0.024*\"evaluasi\" + 0.024*\"pencapresan\" + 0.023*\"buka\" + 0.023*\"mungkin\" + 0.022*\"umum\" + 0.022*\"jika\"\n"
     ]
    }
   ],
   "source": [
    "document_num = 12\n",
    "print(data.iloc[document_num, 0])\n",
    "\n",
    "print(processed_tweets[document_num])\n",
    "\n",
    "for index, score in sorted(lda_model_tfidf[bow_corpus[document_num]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.459434449672699\t Topic: 0.024*\"mau\" + 0.024*\"pdip\" + 0.016*\"ada\" + 0.016*\"dahlan\" + 0.015*\"di\"\n",
      "Score: 0.44666385650634766\t Topic: 0.051*\"prabowo\" + 0.021*\"saya\" + 0.021*\"kalau\" + 0.020*\"pak\" + 0.020*\"megawati\"\n",
      "Score: 0.015661247074604034\t Topic: 0.034*\"wiranto\" + 0.034*\"jk\" + 0.017*\"calon\" + 0.016*\"mantan\" + 0.016*\"dan\"\n",
      "Score: 0.015654154121875763\t Topic: 0.038*\"mantan\" + 0.035*\"kalla\" + 0.034*\"jusuf\" + 0.034*\"dan\" + 0.027*\"dalam\"\n",
      "Score: 0.01564868353307247\t Topic: 0.036*\"saya\" + 0.026*\"di\" + 0.021*\"megawati\" + 0.018*\"dahlan\" + 0.016*\"prabowo\"\n",
      "Score: 0.015646958723664284\t Topic: 0.033*\"di\" + 0.020*\"dahlan\" + 0.019*\"rakyat\" + 0.019*\"jk\" + 0.019*\"pada\"\n",
      "Score: 0.015646163374185562\t Topic: 0.025*\"di\" + 0.023*\"dan\" + 0.018*\"kalla\" + 0.018*\"jusuf\" + 0.017*\"ke\"\n",
      "Score: 0.015644490718841553\t Topic: 0.048*\"hatta\" + 0.026*\"jika\" + 0.025*\"ketua\" + 0.024*\"mungkin\" + 0.023*\"umum\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = \"Saya mendukung Jokowi dan Basuki! PDI-P selamanya!\"\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
