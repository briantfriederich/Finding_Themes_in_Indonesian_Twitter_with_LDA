{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           isi_tweet  sentimen\n",
      "0  tidak setuju jokowi jadi cawapres capres jokow...         1\n",
      "1  capres jokowi wacapres abraham samad gubernur ...         1\n",
      "2  capres prabowo dan cawapres jokowi dan gubdki ...         1\n",
      "3  jadi skenarionya gini 2014 biar prabowo jadi p...         1\n",
      "4  sby mantan tni dan calon presiden prabowo subi...         1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('tweets.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           isi_tweet  index\n",
      "0  tidak setuju jokowi jadi cawapres capres jokow...      0\n",
      "1  capres jokowi wacapres abraham samad gubernur ...      1\n",
      "2  capres prabowo dan cawapres jokowi dan gubdki ...      2\n",
      "3  jadi skenarionya gini 2014 biar prabowo jadi p...      3\n",
      "4  sby mantan tni dan calon presiden prabowo subi...      4\n",
      "\n",
      "1846 tweets in dataset\n"
     ]
    }
   ],
   "source": [
    "data_text = data[['isi_tweet']]\n",
    "data_text['index'] = data_text.index\n",
    "tweets = data_text\n",
    "print(tweets.head())\n",
    "print(\"\\n{} tweets in dataset\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/brianfrieerich/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import Sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "np.random.seed(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Mereka meniru-nirukannya\n",
      "\n",
      "Stemmed: mereka tiru\n"
     ]
    }
   ],
   "source": [
    "factory = StemmerFactory()\n",
    "indoStemmer = factory.create_stemmer()\n",
    "\n",
    "def indoStem(text):\n",
    "    stemmed = indoStemmer.stem(text)\n",
    "    return stemmed\n",
    "\n",
    "sentence = \"Mereka meniru-nirukannya\"\n",
    "\n",
    "print(\"Original: {}\".format(sentence))\n",
    "\n",
    "output = indoStem(sentence)\n",
    "print(\"\\nStemmed: {}\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = []\n",
    "with open('stopwords.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    stopwords_list = list(reader) \n",
    "    flat_stoplist = [item for sublist in stopwords_list for item in sublist]\n",
    "\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    text = re.sub(\"[^a-zA-Z]+\", \" \", text)\n",
    "    stemmed = indoStem(text)\n",
    "    for word in stemmed.split(' '):\n",
    "        if word not in flat_stoplist:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tuju', 'jokowi', 'cawapres', 'capres', 'jokowi', 'harga', 'mati'],\n",
       " ['capres',\n",
       "  'jokowi',\n",
       "  'wacapres',\n",
       "  'abraham',\n",
       "  'samad',\n",
       "  'gubernur',\n",
       "  'ahok',\n",
       "  'koruptor',\n",
       "  'abissss'],\n",
       " ['capres',\n",
       "  'prabowo',\n",
       "  'cawapres',\n",
       "  'jokowi',\n",
       "  'gubdki',\n",
       "  'ahok',\n",
       "  'mantap',\n",
       "  'presiden',\n",
       "  'sby',\n",
       "  'bubar',\n",
       "  'fpi'],\n",
       " ['skenario',\n",
       "  'gin',\n",
       "  'biar',\n",
       "  'prabowo',\n",
       "  'presiden',\n",
       "  'jokowi',\n",
       "  'tetepgubernur',\n",
       "  'jakarta',\n",
       "  'hasil',\n",
       "  'nunggu',\n",
       "  'gantiin',\n",
       "  'prabowo'],\n",
       " ['sby',\n",
       "  'mantan',\n",
       "  'tni',\n",
       "  'calon',\n",
       "  'presiden',\n",
       "  'prabowo',\n",
       "  'subianto',\n",
       "  'mantan',\n",
       "  'kopassus',\n",
       "  'anggoto',\n",
       "  'tni',\n",
       "  'disiplin',\n",
       "  'smw',\n",
       "  'presiden']]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_tweets = list(map(preprocess, tweets['isi_tweet']))\n",
    "processed_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below = 5, no_above = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 1), (5, 1), (36, 2), (39, 1), (51, 2)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(twt) for twt in processed_tweets]\n",
    "bow_corpus[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 4 (\"ahok\") appears 1 time.\n",
      "Word 5 (\"gubernur\") appears 1 time.\n",
      "Word 36 (\"ya\") appears 2 time.\n",
      "Word 39 (\"indonesia\") appears 1 time.\n",
      "Word 51 (\"gila\") appears 2 time.\n"
     ]
    }
   ],
   "source": [
    "bow_tweet_14 = bow_corpus[15]\n",
    "for i in range(len(bow_tweet_14)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_tweet_14[i][0], \n",
    "                                                     dictionary[bow_tweet_14[i][0]], \n",
    "                                                     bow_tweet_14[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.34743145805198594), (1, 0.7326536398654326), (2, 0.5852435612185782)]\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.047*\"prabowo\" + 0.037*\"arb\" + 0.021*\"megawati\" + 0.019*\"indonesia\" + 0.016*\"ahok\" + 0.013*\"wakil\" + 0.013*\"jk\" + 0.012*\"dahlan\" + 0.011*\"sby\" + 0.011*\"risma\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.036*\"dahlan\" + 0.028*\"wiranto\" + 0.018*\"iskan\" + 0.016*\"konvensi\" + 0.016*\"calon\" + 0.014*\"ya\" + 0.014*\"jakarta\" + 0.013*\"megawati\" + 0.011*\"dukung\" + 0.011*\"pasang\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.042*\"mantan\" + 0.035*\"megawati\" + 0.035*\"wakil\" + 0.031*\"jusuf\" + 0.031*\"kalla\" + 0.028*\"gubernur\" + 0.027*\"tokoh\" + 0.025*\"nyata\" + 0.024*\"sosok\" + 0.024*\"dahlan\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.049*\"hatta\" + 0.043*\"wakil\" + 0.041*\"kalla\" + 0.039*\"jusuf\" + 0.038*\"jk\" + 0.034*\"mantan\" + 0.029*\"ketua\" + 0.026*\"buka\" + 0.025*\"cawapres\" + 0.024*\"pencapresan\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.036*\"jk\" + 0.035*\"wakil\" + 0.033*\"prabowo\" + 0.025*\"hatta\" + 0.022*\"cawapres\" + 0.018*\"indonesia\" + 0.018*\"mantan\" + 0.018*\"kalla\" + 0.017*\"jusuf\" + 0.013*\"calon\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics = 5, id2word = dictionary, passes = 2, workers = 4)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.037*\"hatta\" + 0.021*\"buka\" + 0.020*\"ketua\" + 0.019*\"pan\" + 0.019*\"radjasa\" + 0.019*\"pencapresan\" + 0.019*\"evaluasi\" + 0.018*\"prabowo\" + 0.017*\"cawapres\" + 0.016*\"indonesia\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.034*\"prabowo\" + 0.017*\"kalla\" + 0.017*\"jusuf\" + 0.016*\"wakil\" + 0.014*\"mantan\" + 0.014*\"jakarta\" + 0.013*\"tweet\" + 0.012*\"calon\" + 0.012*\"jk\" + 0.012*\"cawapres\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.017*\"megawati\" + 0.016*\"rakyat\" + 0.015*\"pilih\" + 0.014*\"dahlan\" + 0.012*\"risma\" + 0.012*\"nya\" + 0.011*\"arb\" + 0.011*\"jk\" + 0.010*\"p\" + 0.010*\"pdip\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.022*\"jusuf\" + 0.022*\"sosok\" + 0.022*\"nyata\" + 0.022*\"tokoh\" + 0.022*\"kalla\" + 0.022*\"bincang\" + 0.022*\"populer\" + 0.022*\"arb\" + 0.021*\"gubernur\" + 0.020*\"wakil\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.024*\"megawati\" + 0.017*\"jk\" + 0.013*\"politik\" + 0.013*\"mantan\" + 0.011*\"mahfud\" + 0.010*\"calon\" + 0.010*\"md\" + 0.010*\"dukung\" + 0.010*\"dahlan\" + 0.009*\"pilih\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, \n",
    "                                             num_topics=5, \n",
    "                                             id2word = dictionary, \n",
    "                                             passes = 2, \n",
    "                                             workers=4)\n",
    "                                             \n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tong di pilih jadi presiden arb na\n",
      "['tong', 'pilih', 'presiden', 'arb', 'na']\n",
      "\n",
      "Score: 0.7255508303642273\t \n",
      "Topic: 0.047*\"prabowo\" + 0.037*\"arb\" + 0.021*\"megawati\" + 0.019*\"indonesia\" + 0.016*\"ahok\" + 0.013*\"wakil\" + 0.013*\"jk\" + 0.012*\"dahlan\" + 0.011*\"sby\" + 0.011*\"risma\"\n",
      "\n",
      "Score: 0.06907791644334793\t \n",
      "Topic: 0.042*\"mantan\" + 0.035*\"megawati\" + 0.035*\"wakil\" + 0.031*\"jusuf\" + 0.031*\"kalla\" + 0.028*\"gubernur\" + 0.027*\"tokoh\" + 0.025*\"nyata\" + 0.024*\"sosok\" + 0.024*\"dahlan\"\n",
      "\n",
      "Score: 0.06883931905031204\t \n",
      "Topic: 0.036*\"jk\" + 0.035*\"wakil\" + 0.033*\"prabowo\" + 0.025*\"hatta\" + 0.022*\"cawapres\" + 0.018*\"indonesia\" + 0.018*\"mantan\" + 0.018*\"kalla\" + 0.017*\"jusuf\" + 0.013*\"calon\"\n",
      "\n",
      "Score: 0.0685875415802002\t \n",
      "Topic: 0.049*\"hatta\" + 0.043*\"wakil\" + 0.041*\"kalla\" + 0.039*\"jusuf\" + 0.038*\"jk\" + 0.034*\"mantan\" + 0.029*\"ketua\" + 0.026*\"buka\" + 0.025*\"cawapres\" + 0.024*\"pencapresan\"\n",
      "\n",
      "Score: 0.06794441491365433\t \n",
      "Topic: 0.036*\"dahlan\" + 0.028*\"wiranto\" + 0.018*\"iskan\" + 0.016*\"konvensi\" + 0.016*\"calon\" + 0.014*\"ya\" + 0.014*\"jakarta\" + 0.013*\"megawati\" + 0.011*\"dukung\" + 0.011*\"pasang\"\n"
     ]
    }
   ],
   "source": [
    "document_num = 12\n",
    "print(data.iloc[document_num, 0])\n",
    "\n",
    "print(processed_tweets[document_num])\n",
    "\n",
    "for index, score in sorted(lda_model[bow_corpus[document_num]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.7275841236114502\t \n",
      "Topic: 0.017*\"megawati\" + 0.016*\"rakyat\" + 0.015*\"pilih\" + 0.014*\"dahlan\" + 0.012*\"risma\" + 0.012*\"nya\" + 0.011*\"arb\" + 0.011*\"jk\" + 0.010*\"p\" + 0.010*\"pdip\"\n",
      "\n",
      "Score: 0.06952399760484695\t \n",
      "Topic: 0.022*\"jusuf\" + 0.022*\"sosok\" + 0.022*\"nyata\" + 0.022*\"tokoh\" + 0.022*\"kalla\" + 0.022*\"bincang\" + 0.022*\"populer\" + 0.022*\"arb\" + 0.021*\"gubernur\" + 0.020*\"wakil\"\n",
      "\n",
      "Score: 0.06796497851610184\t \n",
      "Topic: 0.024*\"megawati\" + 0.017*\"jk\" + 0.013*\"politik\" + 0.013*\"mantan\" + 0.011*\"mahfud\" + 0.010*\"calon\" + 0.010*\"md\" + 0.010*\"dukung\" + 0.010*\"dahlan\" + 0.009*\"pilih\"\n",
      "\n",
      "Score: 0.0676150694489479\t \n",
      "Topic: 0.034*\"prabowo\" + 0.017*\"kalla\" + 0.017*\"jusuf\" + 0.016*\"wakil\" + 0.014*\"mantan\" + 0.014*\"jakarta\" + 0.013*\"tweet\" + 0.012*\"calon\" + 0.012*\"jk\" + 0.012*\"cawapres\"\n",
      "\n",
      "Score: 0.06731179356575012\t \n",
      "Topic: 0.037*\"hatta\" + 0.021*\"buka\" + 0.020*\"ketua\" + 0.019*\"pan\" + 0.019*\"radjasa\" + 0.019*\"pencapresan\" + 0.019*\"evaluasi\" + 0.018*\"prabowo\" + 0.017*\"cawapres\" + 0.016*\"indonesia\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[document_num]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.83885258436203\t Topic: 0.036*\"dahlan\" + 0.028*\"wiranto\" + 0.018*\"iskan\" + 0.016*\"konvensi\" + 0.016*\"calon\"\n",
      "Score: 0.040394075214862823\t Topic: 0.047*\"prabowo\" + 0.037*\"arb\" + 0.021*\"megawati\" + 0.019*\"indonesia\" + 0.016*\"ahok\"\n",
      "Score: 0.04031170532107353\t Topic: 0.036*\"jk\" + 0.035*\"wakil\" + 0.033*\"prabowo\" + 0.025*\"hatta\" + 0.022*\"cawapres\"\n",
      "Score: 0.04025238752365112\t Topic: 0.049*\"hatta\" + 0.043*\"wakil\" + 0.041*\"kalla\" + 0.039*\"jusuf\" + 0.038*\"jk\"\n",
      "Score: 0.040189217776060104\t Topic: 0.042*\"mantan\" + 0.035*\"megawati\" + 0.035*\"wakil\" + 0.031*\"jusuf\" + 0.031*\"kalla\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = \"Saya mendukung Jokowi dan Basuki! PDI-P selamanya!\"\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
